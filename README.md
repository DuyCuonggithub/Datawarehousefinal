# ğŸ¤– Cuá»‘i ká»³ Khai PhÃ¡ Dá»¯ Liá»‡u & Há»c MÃ¡y 

## ğŸ“Œ Giá»›i Thiá»‡u Dá»± Ãn 

ÄÃ¢y lÃ  dá»± Ã¡n á»©ng dá»¥ng cÃ¡c thuáº­t toÃ¡n Há»c mÃ¡y vÃ  Khai phÃ¡ dá»¯ liá»‡u Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n . Dá»± Ã¡n bao gá»“m cÃ¡c giai Ä‘oáº¡n: tiá»n xá»­ lÃ½ dá»¯ liá»‡u, phÃ¢n tÃ­ch khÃ¡m phÃ¡ (EDA), xÃ¢y dá»±ng mÃ´ hÃ¬nh phÃ¢n loáº¡i (Classification) vÃ  thá»±c hiá»‡n phÃ¢n cá»¥m (Clustering).

Má»¥c tiÃªu chÃ­nh lÃ  tÃ¬m ra mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n hiá»‡u quáº£ nháº¥t vÃ  rÃºt ra cÃ¡c thÃ´ng tin chi tiáº¿t cÃ³ giÃ¡ trá»‹ tá»« dá»¯ liá»‡u.

## ğŸ¯ Má»¥c TiÃªu ChÃ­nh

1.  **Tiá»n xá»­ lÃ½ Dá»¯ liá»‡u:** Xá»­ lÃ½ vÃ  lÃ m sáº¡ch dá»¯ liá»‡u thÃ´ Ä‘á»ƒ tá»‘i Æ°u hÃ³a Ä‘áº§u vÃ o cho cÃ¡c mÃ´ hÃ¬nh Há»c mÃ¡y.
2.  **XÃ¢y dá»±ng MÃ´ hÃ¬nh PhÃ¢n loáº¡i:** Ãp dá»¥ng vÃ  Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a nhiá»u thuáº­t toÃ¡n PhÃ¢n loáº¡i khÃ¡c nhau.
3.  **Thá»±c hiá»‡n PhÃ¢n cá»¥m:** Ãp dá»¥ng PhÃ¢n cá»¥m (Clustering) Ä‘á»ƒ khÃ¡m phÃ¡ cáº¥u trÃºc vÃ  nhÃ³m tá»± nhiÃªn trong dá»¯ liá»‡u.
4.  **ÄÃ¡nh giÃ¡ Hiá»‡u suáº¥t:** So sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ xÃ¢y dá»±ng Ä‘á»ƒ chá»n ra mÃ´ hÃ¬nh tá»‘i Æ°u.

## ğŸ› ï¸ CÃ´ng Cá»¥ vÃ  CÃ´ng Nghá»‡

| CÃ´ng cá»¥ | Tá»‡p Notebook liÃªn quan | Má»¥c Ä‘Ã­ch |
| :--- | :--- | :--- |
| **Python** | `Data_preprocessing.ipynb`, cÃ¡c tá»‡p `.ipynb` khÃ¡c | NgÃ´n ngá»¯ láº­p trÃ¬nh chÃ­nh cho phÃ¢n tÃ­ch vÃ  mÃ´ hÃ¬nh hÃ³a. |
| **Pandas, NumPy** | `Data_preprocessing.ipynb` | Thao tÃ¡c vÃ  tÃ­nh toÃ¡n trÃªn dá»¯ liá»‡u. |
| **Scikit-learn** | Táº¥t cáº£ cÃ¡c tá»‡p mÃ´ hÃ¬nh | Triá»ƒn khai cÃ¡c thuáº­t toÃ¡n ML: Decision Tree, Random Forest, KNN. |
| **Jupyter Notebook** | Táº¥t cáº£ cÃ¡c tá»‡p `.ipynb` | MÃ´i trÆ°á»ng láº­p trÃ¬nh Ä‘á»ƒ ghi chÃ©p vÃ  thá»±c thi code tá»«ng bÆ°á»›c. |

## ğŸ“ Cáº¥u TrÃºc Repository

| TÃªn Tá»‡p | MÃ´ táº£ |
| :--- | :--- |
| `Data_preprocessing.ipynb` | **Giai Ä‘oáº¡n Tiá»n xá»­ lÃ½:** Xá»­ lÃ½ dá»¯ liá»‡u thÃ´, lÃ m sáº¡ch, xá»­ lÃ½ Missing Values, vÃ  chuáº©n hÃ³a/mÃ£ hÃ³a dá»¯ liá»‡u. |
| `preprocessed_data_finalversion.csv` | Dá»¯ liá»‡u sau khi Ä‘Ã£ Ä‘Æ°á»£c tiá»n xá»­ lÃ½ vÃ  sáºµn sÃ ng cho giai Ä‘oáº¡n mÃ´ hÃ¬nh hÃ³a. |
| `Decision_Tree_,_Random_Forest_.ipynb` | XÃ¢y dá»±ng vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh **CÃ¢y Quyáº¿t Ä‘á»‹nh (Decision Tree)** vÃ  **Rá»«ng Ngáº«u nhiÃªn (Random Forest)**. |
| `KNNCK_pynb.ipynb` | XÃ¢y dá»±ng vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh **K-Nearest Neighbors (KNN)**. |
| `Hierarchical.ipynb` | Ãp dá»¥ng thuáº­t toÃ¡n **PhÃ¢n cá»¥m PhÃ¢n cáº¥p (Hierarchical Clustering)** Ä‘á»ƒ khÃ¡m phÃ¡ nhÃ³m dá»¯ liá»‡u. |
| `Final_KHO_(1).ipynb` | Tá»‡p Notebook tá»•ng há»£p cuá»‘i cÃ¹ng (cÃ³ thá»ƒ lÃ  tá»‡p tá»•ng há»£p cÃ¡c mÃ´ hÃ¬nh hoáº·c bÃ¡o cÃ¡o cuá»‘i dá»± Ã¡n). |
| `final_dw.csv` | Táº­p dá»¯ liá»‡u cuá»‘i cÃ¹ng cá»§a dá»± Ã¡n (Data Warehouse/Final Data). |

## ğŸ§ª Káº¿t Quáº£ vÃ  PhÃ¢n TÃ­ch MÃ´ HÃ¬nh

Dá»± Ã¡n Ä‘Ã£ táº­p trung vÃ o cÃ¡c thuáº­t toÃ¡n sau:

### 1. PhÃ¢n loáº¡i (Classification)
* **Decision Tree & Random Forest:** ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t dá»± Ä‘oÃ¡n (Accuracy, F1-Score, v.v.) cá»§a hai mÃ´ hÃ¬nh cÃ¢y nÃ y.
* **K-Nearest Neighbors (KNN):** PhÃ¢n tÃ­ch hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh KNN vÃ  tá»‘i Æ°u hÃ³a tham sá»‘ K.

### 2. PhÃ¢n cá»¥m (Clustering)
* **Hierarchical Clustering:** Ãp dá»¥ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¡c nhÃ³m tá»± nhiÃªn trong dá»¯ liá»‡u, há»— trá»£ cho viá»‡c phÃ¢n khÃºc khÃ¡ch hÃ ng hoáº·c nháº­n dáº¡ng máº«u.

[**Ghi chÃº:** *Báº¡n nÃªn bá»• sung thÃªm káº¿t quáº£ cá»¥ thá»ƒ á»Ÿ Ä‘Ã¢y, vÃ­ dá»¥: "MÃ´ hÃ¬nh Random Forest Ä‘áº¡t Accuracy cao nháº¥t lÃ  85%."*]

## ğŸ’¡ HÆ°á»›ng PhÃ¡t Triá»ƒn TÆ°Æ¡ng Lai

* Thá»­ nghiá»‡m cÃ¡c mÃ´ hÃ¬nh Há»c mÃ¡y phá»©c táº¡p hÆ¡n (vÃ­ dá»¥: Support Vector Machines, Gradient Boosting).
* Thá»±c hiá»‡n tá»‘i Æ°u hÃ³a siÃªu tham sá»‘ (Hyperparameter Tuning) chuyÃªn sÃ¢u hÆ¡n.
* XÃ¢y dá»±ng giao diá»‡n Ä‘Æ¡n giáº£n (vÃ­ dá»¥: Streamlit) Ä‘á»ƒ trá»±c quan hÃ³a káº¿t quáº£ dá»± Ä‘oÃ¡n.
